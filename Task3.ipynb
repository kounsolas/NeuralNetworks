{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Append: b'training batch 1 of 5'\n",
      "Append: b'training batch 2 of 5'\n",
      "Append: b'training batch 3 of 5'\n",
      "Append: b'training batch 4 of 5'\n",
      "Append: b'training batch 5 of 5'\n",
      "Append: b'testing batch 1 of 1'\n",
      "Shape X_train: (50000, 3072)\n",
      "Shape y_train: (50000,)\n",
      "Shape X_test: (10000, 3072)\n",
      "Shape y_test: (10000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os   #helps me erase a warning that i am gettin\n",
    "import numpy as np  #the data are numpy when i first get them\n",
    "from sklearn.preprocessing import StandardScaler #i will use this to scale the data\n",
    "from sklearn.decomposition import PCA #i will use this to reduce the dimensionality of the data\n",
    "from sklearn.cluster import KMeans #i will use this to cluster the data\n",
    "\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"8\"  # This line erases a warning that i am getting\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] #the names of the classes      \n",
    "\n",
    "file_names = []\n",
    "files = []\n",
    "#create X_train, y_train, X_test, y_test\n",
    "X_train = np.full((50000,3072),0,dtype=int)\n",
    "X_test = np.full((10000,3072),0,dtype=int)\n",
    "y_train = np.full((50000,),0,dtype=int)\n",
    "y_test = np.full((10000,),0,dtype=int)\n",
    "\n",
    "# the unpickle() function loads the CIFAR-10 data from the file\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Creating a list with the names of the files\n",
    "for i in range(1,6):\n",
    "    file = f\"data_batch_{i}\"\n",
    "    file_names.append(file)\n",
    "file_names.append(\"test_batch\")\n",
    "\n",
    "#storing the unpickled dictionaries to a list\n",
    "for file in file_names:\n",
    "    cifar10_dict = unpickle(file)\n",
    "    files.append(cifar10_dict)\n",
    "\n",
    "# Splitting the data to train and test set\n",
    "# Printing the shapes to make sure that everything went well\n",
    "i=0\n",
    "for file in files:\n",
    "    print(f\"Append: {file[b'batch_label']}\")\n",
    "    if file[b'batch_label'] != b'testing batch 1 of 1':\n",
    "        #this is the X_train, y_train\n",
    "        X_train[i*10000:(i+1)*10000,:] = file[b'data']\n",
    "        y_train[i*10000:(i+1)*10000] = file[b'labels'] \n",
    "        i+=1\n",
    "       \n",
    "    else:\n",
    "        #i have just finished X_train, y_train   \n",
    "        #this is the X_test, y_test\n",
    "        X_test[:,:] = file[b'data']\n",
    "        y_test[:] = file[b'labels']\n",
    "        print(f\"Shape X_train: {X_train.shape}\\nShape y_train: {y_train.shape}\")\n",
    "        print(f\"Shape X_test: {X_test.shape}\\nShape y_test: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class mRBF:\n",
    "    def __init__(self, sigma, n_clusters):\n",
    "        self.sigma = sigma\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = None\n",
    "        self.cluster_centers_ = None\n",
    "        self.cluster_labels_ = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Perform k-means clustering to find cluster centers\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=0).fit(X_train)\n",
    "        self.cluster_centers_ = self.kmeans.cluster_centers_\n",
    "        self.cluster_labels_ = self.kmeans.labels_\n",
    "        self.y_train = y_train\n",
    "        self.sigma = dmax / np.sqrt(2 * self.n_clusters)\n",
    "\n",
    "    def radial_basis_function(self, x_input, center):\n",
    "        return np.exp(-np.linalg.norm(x_input - center) ** 2 / (2 * self.sigma ** 2))\n",
    "    \n",
    "    def approximating_function(self, x_input,y_test):\n",
    "        # Compute the RBF outputs for each cluster center\n",
    "        rbf_outputs = np.array([self.radial_basis_function(x_input, center) for center in self.cluster_centers_])\n",
    "        \n",
    "        # Initialize an array to store the sum of RBF outputs for each class\n",
    "        class_scores = np.zeros(len(np.unique(self.y_train)))\n",
    "        \n",
    "        # Sum the RBF outputs for each class\n",
    "        for i, score in enumerate(rbf_outputs):\n",
    "            class_scores[y_test[i]] += score\n",
    "        \n",
    "        # Choose the class with the highest score\n",
    "        predicted_class = np.argmax(class_scores)\n",
    "        return predicted_class\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mRBF(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=0.9)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pca shape: (50000, 103)\n",
      "X_test_pca shape: (10000, 103)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_pca shape: {X_train_pca.shape}\")\n",
    "print(f\"X_test_pca shape: {X_test_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1239\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sigma = 1\n",
    "n_clusters = 10\n",
    "model = mRBF(sigma, n_clusters)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict the class for each sample in X_test_pca\n",
    "predicted_classes = [model.approximating_function(x,y_test) for x in X_test_pca]\n",
    "acc = accuracy_score(y_test, predicted_classes)\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0927\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class mRBF:\n",
    "    def __init__(self, n_clusters,sigma = None):\n",
    "        self.sigma = sigma\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = None\n",
    "        self.cluster_centers_ = None\n",
    "        self.cluster_labels_ = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Perform k-means clustering to find cluster centers\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=0).fit(X_train)\n",
    "        self.cluster_centers_ = self.kmeans.cluster_centers_\n",
    "        self.cluster_labels_ = self.kmeans.labels_\n",
    "        self.y_train = y_train\n",
    "\n",
    "        # Calculate the maximum distance between cluster centers\n",
    "        pairwise_distances = cdist(self.cluster_centers_, self.cluster_centers_, 'euclidean')\n",
    "        dmax = np.max(pairwise_distances)\n",
    "        \n",
    "        # Set sigma using the maximum distance\n",
    "        self.sigma = dmax / np.sqrt(2 * self.n_clusters)\n",
    "\n",
    "    def radial_basis_function(self, x_input, center):\n",
    "        return np.exp(-np.linalg.norm(x_input - center) ** 2 / (2 * self.sigma ** 2))\n",
    "    \n",
    "    def approximating_function(self, x_input):\n",
    "        # Compute the RBF outputs for each cluster center\n",
    "        rbf_outputs = np.array([self.radial_basis_function(x_input, center) for center in self.cluster_centers_])\n",
    "        \n",
    "        # Initialize an array to store the sum of RBF outputs for each class\n",
    "        class_scores = np.zeros(len(np.unique(self.y_train)))\n",
    "        \n",
    "        # Sum the RBF outputs for each class\n",
    "        for i, score in enumerate(rbf_outputs):\n",
    "            # Find the class label for the cluster center\n",
    "            cluster_label = self.cluster_labels_[i]\n",
    "            class_label = self.y_train[cluster_label]\n",
    "            class_scores[class_label] += score\n",
    "        \n",
    "        # Choose the class with the highest score\n",
    "        predicted_class = np.argmax(class_scores)\n",
    "        return predicted_class\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Predict the class for each sample in X_test\n",
    "        predictions = np.array([self.approximating_function(x_input) for x_input in X_test])\n",
    "        return predictions\n",
    "\n",
    "# Example usage\n",
    "n_clusters = 20\n",
    "model = mRBF(n_clusters)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict the classes for the test set\n",
    "predictions = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
